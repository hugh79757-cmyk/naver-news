import os
from dotenv import load_dotenv
from src import crawler, analyzer, builder

# .env íŒŒì¼ì—ì„œ í™˜ê²½ë³€ìˆ˜ ë¡œë“œ (ë¡œì»¬ ì‹¤í–‰ìš©)
load_dotenv()

def main():
    print("ğŸš€ ë‰´ìŠ¤ ë´‡ ê°€ë™ ì‹œì‘...")
    
    all_headlines = []

    # 1. ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ (ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰)
    naver_news = crawler.fetch_naver_ranking_news()
    if naver_news:
        all_headlines.extend(naver_news)
    else:
        print("âš ï¸ ë„¤ì´ë²„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ (ê±´ë„ˆëœ€)")

    # 2. ì •ì±…ë¸Œë¦¬í•‘ ìˆ˜ì§‘ (ë…ë¦½ ì‹¤í–‰)
    policy_news = crawler.fetch_policy_api()
    if policy_news:
        all_headlines.extend(policy_news)
    else:
        print("âš ï¸ ì •ì±…ë¸Œë¦¬í•‘ ìˆ˜ì§‘ ì‹¤íŒ¨ (ê±´ë„ˆëœ€)")

    # 3. ë°ì´í„°ê°€ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ ë¶„ì„ ì‹œì‘
    if not all_headlines:
        print("âŒ ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì „í˜€ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    print(f"ğŸ“Š ì´ {len(all_headlines)}ê°œì˜ í—¤ë“œë¼ì¸ì„ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    # ... (ì´í›„ ë¶„ì„ ë° ë¹Œë“œ ì½”ë“œëŠ” ê·¸ëŒ€ë¡œ)

        # ... (ë„¤ì´ë²„ ìˆ˜ì§‘ ì½”ë“œ ì•„ë˜ì— ì¶”ê°€)
    
    # 3. ë‹¤ìŒ ë‰´ìŠ¤ ìˆ˜ì§‘ (New!)
    daum_news = crawler.fetch_daum_news()
    if daum_news:
        all_headlines.extend(daum_news)
    else:
        print("âš ï¸ ë‹¤ìŒ ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨ (ê±´ë„ˆëœ€)")

